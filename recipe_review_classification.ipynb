{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28528caf-9f36-4261-a742-472c89d92859",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2fbaa14-d532-47f0-bd7a-0ba77a7ad1e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7397f24-03cc-4b05-a924-a64a00ab0ad6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recipes = spark.read.option(\"sep\", \",\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"header\", \"true\").option(\"multiline\", \"true\").csv(\"recipes.csv\")\n",
    "reviews = spark.read.option(\"sep\", \",\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"header\", \"true\").option(\"multiline\", \"true\").csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "302a7fc9-2834-4ad9-8c89-b9540a158c35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recipes.createOrReplaceTempView(\"recipes\")\n",
    "reviews.createOrReplaceTempView(\"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03bdc39d-d2f7-4f77-aa19-d7bf1415d7bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select *\n",
    "# from recipes\n",
    "# limit 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cd534e3-d0db-4225-b5dd-0907b0a6d952",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recipes_clean = spark.sql(\"\"\"\n",
    "select RecipeId, Description, RecipeInstructions, ReviewCount, CookTime, PrepTime, RecipeCategory, RecipeIngredientParts, AggregatedRating, Calories, FatContent, SaturatedFatContent, CholesterolContent, SodiumContent, CarbohydrateContent, FiberContent, SugarContent, ProteinContent, RecipeServings \n",
    "from recipes\n",
    "where AggregatedRating != 'NA' and ReviewCount > 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61b2381a-0bb9-410f-ba8a-f3e5c0a954e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# recipes_clean = spark.sql(\"\"\"\n",
    "# select RecipeId, Description, RecipeInstructions, ReviewCount, CookTime, PrepTime, RecipeCategory, RecipeIngredientParts, AggregatedRating, Calories, FatContent, SaturatedFatContent, CholesterolContent, SodiumContent, CarbohydrateContent, FiberContent, SugarContent, ProteinContent, RecipeServings \n",
    "# from recipes\n",
    "# where AggregatedRating != 'NA'\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb282277-028b-4556-b7c2-2b3cb6abbe88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recipes_clean.createOrReplaceTempView(\"recipes_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0f64ad0-5c0e-4a8b-ae50-49497aec6f51",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b89f0bf-a553-4106-8941-1fbc1c8c1049",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Feature: CookDuration, PrepDuration\n",
    "recipes_clean = recipes_clean.withColumn('CookHours', F.regexp_extract(F.col('CookTime'), '(\\d+)(?=H)', 0).cast('int'))\n",
    "recipes_clean = recipes_clean.withColumn('CookMinutes', F.regexp_extract(F.col('CookTime'), '(\\d+)(?=M)', 0).cast('int'))\n",
    "recipes_clean = recipes_clean.fillna({'CookHours': 0, 'CookMinutes': 0})\n",
    "recipes_clean = recipes_clean.withColumn('CookDuration', recipes_clean['CookHours'] * 60 + recipes_clean['CookMinutes'])\n",
    "\n",
    "recipes_clean = recipes_clean.withColumn('PrepHours', F.regexp_extract(F.col('PrepTime'), '(\\d+)(?=H)', 0).cast('int'))\n",
    "recipes_clean = recipes_clean.withColumn('PrepMinutes', F.regexp_extract(F.col('PrepTime'), '(\\d+)(?=M)', 0).cast('int'))\n",
    "recipes_clean = recipes_clean.fillna({'PrepHours': 0, 'PrepMinutes': 0})\n",
    "recipes_clean = recipes_clean.withColumn('PrepDuration', recipes_clean['PrepHours'] * 60 + recipes_clean['PrepMinutes'])\n",
    "\n",
    "recipes_clean = recipes_clean.drop(*['CookTime', 'CookHours', 'CookMinutes', 'PrepTime', 'PrepHours', 'PrepMinutes'])\n",
    "\n",
    "### Feature: DescriptionLen\n",
    "recipes_clean = recipes_clean.withColumn('DescriptionLen', F.length(recipes_clean['Description']))\n",
    "recipes_clean = recipes_clean.drop('Description')\n",
    "\n",
    "### Feature: RecipeIngredientPartsCount\n",
    "recipes_clean = recipes_clean.withColumn('RecipeIngredientPartsCount', F.size(F.split(F.col('RecipeIngredientParts'), ',')))\n",
    "recipes_clean = recipes_clean.drop('RecipeIngredientParts')\n",
    "\n",
    "### Feature: RecipeInstructionSteps\n",
    "recipes_clean = recipes_clean.withColumn('RecipeInstructionSteps', F.size(F.split(F.col('RecipeInstructions'), ',')))\n",
    "recipes_clean = recipes_clean.drop('RecipeInstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b97e3de-4935-42be-a406-037cfa0b6daf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|RecipeCategory  |count|\n",
      "+----------------+-----+\n",
      "|Other           |17860|\n",
      "|Dessert         |17278|\n",
      "|Lunch/Snacks    |11701|\n",
      "|One Dish Meal   |11147|\n",
      "|Vegetable       |9546 |\n",
      "|Breakfast       |7122 |\n",
      "|Beverages       |5567 |\n",
      "|Chicken         |5076 |\n",
      "|Pork            |4559 |\n",
      "|Breads          |4380 |\n",
      "|Potato          |4297 |\n",
      "|Chicken Breast  |4275 |\n",
      "|Quick Breads    |4217 |\n",
      "|Meat            |4096 |\n",
      "|Sauces          |3875 |\n",
      "|Cheese          |3102 |\n",
      "|Bar Cookie      |2561 |\n",
      "|Drop Cookies    |2404 |\n",
      "|Pie             |2375 |\n",
      "|Yeast Breads    |2263 |\n",
      "|< 60 Mins       |2050 |\n",
      "|Stew            |1964 |\n",
      "|< 30 Mins       |1940 |\n",
      "|Salad Dressings |1684 |\n",
      "|Candy           |1684 |\n",
      "|Beans           |1669 |\n",
      "|Low Protein     |1622 |\n",
      "|< 15 Mins       |1557 |\n",
      "|Spreads         |1491 |\n",
      "|Smoothies       |1321 |\n",
      "|Poultry         |1158 |\n",
      "|Steak           |1151 |\n",
      "|Frozen Desserts |1101 |\n",
      "|Onions          |1096 |\n",
      "|Savory Pies     |1040 |\n",
      "|Curries         |1001 |\n",
      "|Rice            |998  |\n",
      "|European        |980  |\n",
      "|Very Low Carbs  |936  |\n",
      "|Cheesecake      |919  |\n",
      "|Low Cholesterol |898  |\n",
      "|Corn            |837  |\n",
      "|< 4 Hours       |832  |\n",
      "|Fruit           |806  |\n",
      "|Yam/Sweet Potato|773  |\n",
      "|Grains          |741  |\n",
      "|Spinach         |727  |\n",
      "|Chowders        |721  |\n",
      "|Punch Beverage  |635  |\n",
      "|Spaghetti       |629  |\n",
      "+----------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Aggregate RecipeCategory\n",
    "category_counts = recipes_clean.groupBy('RecipeCategory').agg(F.countDistinct('RecipeId').alias('CategoryCount'))\n",
    "recipes_clean = recipes_clean.join(category_counts, on = 'RecipeCategory', how = 'left')\n",
    "recipes_clean = recipes_clean.withColumn('RecipeCategory', F.when(F.col('CategoryCount') < 500, 'Other').otherwise(F.col('RecipeCategory')))\n",
    "recipes_clean = recipes_clean.drop('CategoryCount')\n",
    "recipes_clean.groupBy('RecipeCategory').agg(F.countDistinct('RecipeId').alias('count')).orderBy(F.desc('count')).show(50,truncate=False)\n",
    "\n",
    "### Feature: dummy variables based on RecipeCategory\n",
    "indexer = StringIndexer(inputCol='RecipeCategory', outputCol='RecipeCategoryIndex')\n",
    "recipes_clean = indexer.fit(recipes_clean).transform(recipes_clean)\n",
    "encoder = OneHotEncoder(inputCol='RecipeCategoryIndex', outputCol='RecipeCategoryVec')\n",
    "recipes_clean = encoder.fit(recipes_clean).transform(recipes_clean)\n",
    "\n",
    "recipe_category_index_mapping = recipes_clean.select(['RecipeCategory', 'RecipeCategoryIndex']).distinct()\n",
    "# display(recipe_category_index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3092c0ba-4b01-45d6-ac5d-28ca3dc425e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|AggregatedRating| count|\n",
      "+----------------+------+\n",
      "|               1|   225|\n",
      "|             1.5|    76|\n",
      "|               2|   328|\n",
      "|             2.5|   673|\n",
      "|               3|  2755|\n",
      "|             3.5|  3978|\n",
      "|               4| 16063|\n",
      "|             4.5| 34330|\n",
      "|               5|109201|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### prepare response variable\n",
    "### try multi class classification\n",
    "# recipes_clean = recipes_clean.withColumn('AggregatedRatingBucket', F.when(recipes_clean['AggregatedRating'].isin([1, 1.5, 2, 2.5]), 'low').when(recipes_clean['AggregatedRating'].isin([3, 3.5, 4]), 'medium').otherwise('high'))\n",
    "# recipes_clean = recipes_clean.withColumn('AggregatedRatingBucket', F.when(recipes_clean['AggregatedRatingBucket']=='low', '1').when(recipes_clean['AggregatedRatingBucket'] == 'medium', '2').otherwise('3'))\n",
    "### change to binary class classification\n",
    "recipes_clean.groupBy('AggregatedRating').count().orderBy('AggregatedRating').show()\n",
    "recipes_clean = recipes_clean.withColumn('AggregatedRatingBucket', F.when(recipes_clean['AggregatedRating'].isin([1, 1.5, 2, 2.5, 3, 3.5]), 'low').otherwise('high'))\n",
    "recipes_clean = recipes_clean.withColumn('AggregatedRatingBucket', F.when(recipes_clean['AggregatedRatingBucket']=='low', '1').otherwise('0'))\n",
    "recipes_clean = recipes_clean.withColumn('AggregatedRatingBucket', recipes_clean['AggregatedRatingBucket'].cast(IntegerType()))\n",
    "recipes_clean = recipes_clean.drop('AggregatedRating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "071c1ab6-d5b6-4de5-a6d1-78d5e20a5427",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "|AggregatedRatingBucket| count|\n",
      "+----------------------+------+\n",
      "|                     0|159594|\n",
      "|                     1|  8035|\n",
      "+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipes_clean.groupBy('AggregatedRatingBucket').count().orderBy('AggregatedRatingBucket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07dedc4b-1da0-4ee3-8a01-d65a9cb1e312",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### convert string columns to numerical columns\n",
    "cols_to_convert = ['DescriptionLen', 'RecipeInstructionSteps', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings']\n",
    "for col_name in cols_to_convert:\n",
    "    recipes_clean = recipes_clean.withColumn(col_name, recipes_clean[col_name].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38b72d3-43fa-492f-84e2-a3f36fd6eecc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------------+------------------+----------------+-------------------+------------------+------------------+-------------------+-----------------+-----------------+------------------+------------------+\n",
      "|summary|    DescriptionLen|RecipeInstructionSteps|          Calories|      FatContent|SaturatedFatContent|CholesterolContent|     SodiumContent|CarbohydrateContent|     FiberContent|     SugarContent|    ProteinContent|    RecipeServings|\n",
      "+-------+------------------+----------------------+------------------+----------------+-------------------+------------------+------------------+-------------------+-----------------+-----------------+------------------+------------------+\n",
      "|  count|            167629|                167629|            167629|          167629|             167629|            167629|            167629|             167629|           167629|           167629|            167629|            106357|\n",
      "|   mean|202.45951476176558|    12.370812926164326|472.02858518805994|23.6261959491768|  9.213367616181108| 84.07137669982455| 777.4990955168512|  48.30521627841848|3.677343419220703|21.33115869113687|17.356891709966643| 8.281081640136522|\n",
      "| stddev|174.58500269541858|    7.7894919986742135| 779.6325272787603|50.1974897536323|  23.99789912172912|184.76594745848104|3976.6733703446903|  98.19252582385056|9.519005031702509|67.01651625873696| 28.93581828735856|103.99041355891957|\n",
      "|    min|               2.0|                   1.0|               0.0|             0.0|                0.0|               0.0|               0.0|                0.0|              0.0|              0.0|               0.0|               1.0|\n",
      "|    max|            6325.0|                 164.0|           90904.2|          9491.0|             5869.7|           37224.0|          731056.4|             7695.8|           3012.0|           4735.8|            3276.2|           32767.0|\n",
      "+-------+------------------+----------------------+------------------+----------------+-------------------+------------------+------------------+-------------------+-----------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipes_clean.select(cols_to_convert).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b707e766-70f3-400d-9f6d-cce409934a52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### check missing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc115820-ec4f-4d4c-9d5c-d7afbf6fd73c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# missing_rates = recipes_clean.select([(F.count(F.when(F.col(c).isNull(), c))/recipes_clean.count()).alias(c) for c in cols_to_convert]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e2c6b2-041e-49bf-8206-2af73c79d6e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recipes_clean = recipes_clean.fillna(0, subset=cols_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10d1c8dc-317d-455a-845e-7cbcb26b972a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recipes_clean = recipes_clean.drop(*['RecipeCategory', 'ReviewCount', 'RecipeId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0ddd6bd-2bdb-4a36-85e8-792885f4e393",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### check association direction between features and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad2ce32-f06e-4304-9ec9-74074326e2df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# feature_cols = ['DescriptionLen', 'RecipeInstructionSteps', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', \n",
    "#     'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings', \n",
    "#     'CookDuration', 'PrepDuration', 'RecipeIngredientPartsCount'] \n",
    "# response_col = 'AggregatedRatingBucket'\n",
    "\n",
    "# for feature_col in feature_cols:\n",
    "#     correlation = recipes_clean.stat.corr(feature_col, response_col)\n",
    "#     print(f\"Correlation between {feature_col} and {response_col}: {round(correlation, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5c3f3f0-f462-4f04-8be8-d7cec3bc976b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea8baf16-0a1f-4cef-98a0-7b7c49c4909f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### upsampling minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2dfe08f-e071-4d45-a101-9777ede7678f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Calculating the ratio of weights to oversample\n",
    "# score1_df = recipes_clean.filter(F.col(\"AggregatedRatingBucket\") == 1)\n",
    "# score2_df = recipes_clean.filter(F.col(\"AggregatedRatingBucket\") == 2)\n",
    "# score3_df = recipes_clean.filter(F.col(\"AggregatedRatingBucket\") == 3)\n",
    "\n",
    "# ratio_3_1 = int(score3_df.count()/score1_df.count())\n",
    "# ratio_3_2 = int(score3_df.count()/score2_df.count())\n",
    "\n",
    "# print(\"ratio_3_1: {}\".format(ratio_3_1))\n",
    "# print(\"ratio_3_2: {}\".format(ratio_3_2))\n",
    "\n",
    "# # duplicate the minority rows in Successful state\n",
    "# up1_df = score1_df.withColumn(\"dummy\", F.explode(F.array([F.lit(x) for x in range(int(ratio_3_1+1))]))).drop('dummy')\n",
    "# # combine both oversampled successful rows and previous majority rows \n",
    "# score3_df = score3_df.unionAll(up1_df)\n",
    "\n",
    "# # duplicate the minority rows in Successful state\n",
    "# up2_df = score2_df.withColumn(\"dummy\", F.explode(F.array([F.lit(x) for x in range(int(ratio_3_2+1))]))).drop('dummy')\n",
    "# # combine both oversampled successful rows and previous majority rows \n",
    "# score3_df = score3_df.unionAll(up2_df)\n",
    "\n",
    "# recipes_clean_up = score3_df\n",
    "# # recipes_clean_up.groupBy('AggregatedRatingBucket').count().orderBy('AggregatedRatingBucket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62af4451-37f3-4847-8e2f-4f07487139f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Calculating the ratio of weights to oversample\n",
    "# score0_df = recipes_clean.filter(F.col(\"AggregatedRatingBucket\") == 0)\n",
    "# score1_df = recipes_clean.filter(F.col(\"AggregatedRatingBucket\") == 1)\n",
    "\n",
    "# ratio_1_0 = int(score1_df.count()/score0_df.count())\n",
    "\n",
    "# print(\"ratio_1_0: {}\".format(ratio_1_0))\n",
    "\n",
    "# # duplicate the minority rows in Successful state\n",
    "# up0_df = score0_df.withColumn(\"dummy\", F.explode(F.array([F.lit(x) for x in range(int(ratio_1_0+1))]))).drop('dummy')\n",
    "# # combine both oversampled successful rows and previous majority rows \n",
    "# score1_df = score1_df.unionAll(up0_df)\n",
    "\n",
    "# recipes_clean_up = score1_df\n",
    "# # recipes_clean_up.groupBy('AggregatedRatingBucket').count().orderBy('AggregatedRatingBucket').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89009be4-a4ab-4036-98c8-70f9ae9b0253",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df99cb5-4096-4e8a-8542-a582acff2cc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### use upsampling\n",
    "# train, test = recipes_clean_up.randomSplit([0.7, 0.3], seed = 123)\n",
    "\n",
    "### not use upsampling\n",
    "train, test = recipes_clean.randomSplit([0.7, 0.3], seed = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3128ffd7-b589-49a4-bef1-47c6433cc7e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### downsample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725361de-23bf-48c1-835c-82fe3dae6eb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train.groupBy('AggregatedRatingBucket').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df4013d3-513e-4ddf-b644-2bb956e56ad4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "score0_df = train.filter(F.col('AggregatedRatingBucket') == 0)\n",
    "score1_df = train.filter(F.col('AggregatedRatingBucket') == 1)\n",
    "ratio = int(score0_df.count()/score1_df.count())\n",
    "print(ratio)\n",
    "\n",
    "sampled_score0_df = score0_df.sample(False, 1/ratio)\n",
    "train_down = sampled_score0_df.unionAll(score1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0af21bf2-5110-467c-885a-8c4ffef88b33",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b23858f-402e-4abc-bce8-a66ceec508ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['DescriptionLen', 'RecipeInstructionSteps', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', \n",
    "    'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings', \n",
    "    'CookDuration', 'PrepDuration', 'RecipeIngredientPartsCount', 'RecipeCategoryVec'],\n",
    "    outputCol='features')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"AggregatedRatingBucket\", featuresCol=\"features\", numTrees=500)\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "model = pipeline.fit(train)\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b98b7ff4-3e50-4531-b9ae-3dcf6d380f3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.9294897348025476\n"
     ]
    }
   ],
   "source": [
    "# AUC\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol='AggregatedRatingBucket')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6d97a9f-885d-4fbb-97f5-4cf38d0ac475",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"AggregatedRatingBucket\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb33825a-42bf-4266-9091-b47f01c91545",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Confustion matrix\n",
    "preds_and_labels = predictions.select(['prediction','AggregatedRatingBucket']).withColumn('AggregatedRatingBucket', F.col('AggregatedRatingBucket').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "preds_and_labels = preds_and_labels.select(['prediction','AggregatedRatingBucket'])\n",
    "\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ff88245-9d0d-4689-a02c-91d7170095c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Precision and recall\n",
    "# Class-0\n",
    "print('\\n--------------Class-0----------------')\n",
    "print('Precision          :', round(metrics.precision(0), 3))\n",
    "print('recall             :', round(metrics.recall(0), 3))\n",
    "\n",
    "# Class-1\n",
    "print('\\n--------------Class-1----------------')\n",
    "print('Precision          :', round(metrics.precision(1), 3))\n",
    "print('recall             :', round(metrics.recall(1), 3))\n",
    "\n",
    "# # Class-3\n",
    "# print('\\n--------------Class-3----------------')\n",
    "# print('Precision          :', round(metrics.precision(3), 3))\n",
    "# print('recall             :', round(metrics.recall(3), 3))\n",
    "\n",
    "# Overall Accuracy\n",
    "print('\\n Overall Accuracy:', round(metrics.accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5969a88-2e4d-472e-b6f8-d1e1a4b6f73d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Plot feature importance for top 20 variables\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importances from the model\n",
    "feature_importances = model.stages[-1].featureImportances\n",
    "print(len(feature_importances))\n",
    "\n",
    "# Convert indices to feature names\n",
    "feature_names = ['DescriptionLen', 'RecipeInstructionSteps', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', \n",
    "    'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings', \n",
    "    'CookDuration', 'PrepDuration', 'RecipeIngredientPartsCount', 'RecipeCategoryVec']  # replace with your feature names\n",
    "\n",
    "num_binary_features = len(feature_importances) - 15\n",
    "binary_feature_names = ['RecipeCategoryVec_' + str(i) for i in range(num_binary_features)]\n",
    "feature_names = feature_names + binary_feature_names\n",
    "\n",
    "importances = {feature_names[i]: importance for i, importance in enumerate(feature_importances)}\n",
    "\n",
    "# Convert to pandas DataFrame for easier plotting\n",
    "importances_df = pd.DataFrame(list(importances.items()), columns=['Feature', 'Importance'])\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "importances_df = importances_df.iloc[0:20, :]\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_df['Feature'], importances_df['Importance'], color='skyblue')\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4130c58d-b714-4538-beeb-b141ebb7f7a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### multinomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2a98181-c057-4859-95c2-944017c1e5e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['DescriptionLen', 'RecipeInstructionSteps', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', \n",
    "    'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings', \n",
    "    'CookDuration', 'PrepDuration', 'RecipeIngredientPartsCount', 'RecipeCategoryVec'],\n",
    "    outputCol='features')\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'AggregatedRatingBucket', maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "model = pipeline.fit(train)\n",
    "lrModel = model.stages[-1]\n",
    "\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98e8cd45-ad4a-4fbe-b1f9-d3a4c925d19a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b3b6cf-580e-4e10-9f82-0ece17608e82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Getting the training summary\n",
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "101819b8-892c-47ce-ad0b-df6414318371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AUC\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol='AggregatedRatingBucket')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08244454-5b98-4d02-a117-9a3181796e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"AggregatedRatingBucket\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a936c95-6fe9-4212-8141-ea478b7cc6c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "preds_and_labels = predictions.select(['prediction','AggregatedRatingBucket']).withColumn('AggregatedRatingBucket', F.col('AggregatedRatingBucket').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels = preds_and_labels.select(['prediction','AggregatedRatingBucket'])\n",
    "\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "855eaca8-742f-4da1-91d1-3653727bd9e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Precision and recall\n",
    "# Class-0\n",
    "print('\\n--------------Class-0----------------')\n",
    "print('Precision          :', round(metrics.precision(0), 3))\n",
    "print('recall             :', round(metrics.recall(0), 3))\n",
    "\n",
    "# Class-1\n",
    "print('\\n--------------Class-1----------------')\n",
    "print('Precision          :', round(metrics.precision(1), 3))\n",
    "print('recall             :', round(metrics.recall(1), 3))\n",
    "\n",
    "# Overall Accuracy\n",
    "print('\\n Overall Accuracy:', round(metrics.accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7052fbb4-a84f-4041-b211-429c5fb7b240",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # for multiclass, we can inspect metrics on a per-label basis\n",
    "# print(\"False positive rate by label:\")\n",
    "# for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "#     print(\"label %d: %s\" % (i, round(rate, 4)))\n",
    "\n",
    "# print(\"True positive rate by label:\")\n",
    "# for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "#     print(\"label %d: %s\" % (i, round(rate, 4)))\n",
    "\n",
    "# print(\"Precision by label:\")\n",
    "# for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "#     print(\"label %d: %s\" % (i, round(prec, 4)))\n",
    "\n",
    "# print(\"Recall by label:\")\n",
    "# for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "#     print(\"label %d: %s\" % (i, round(rec, 4)))\n",
    "\n",
    "# print(\"F-measure by label:\")\n",
    "# for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "#     print(\"label %d: %s\" % (i, round(f, 4)))\n",
    "\n",
    "# accuracy = trainingSummary.accuracy\n",
    "# falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "# truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "# fMeasure = trainingSummary.weightedFMeasure()\n",
    "# precision = trainingSummary.weightedPrecision\n",
    "# recall = trainingSummary.weightedRecall\n",
    "# print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "#           % (round(accuracy, 4), round(falsePositiveRate, 4), round(truePositiveRate, 4), round(fMeasure, 4), round(precision, 4), round(recall, 4)))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3097734999643790,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "recipe_review_classification",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
